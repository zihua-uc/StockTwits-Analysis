{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure PySpark environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.pyspark.python': 'python3', 'spark.pyspark.virtualenv.enabled': 'true', 'spark.pyspark.virtualenv.type': 'native', 'spark.pyspark.virtualenv.bin.path': '/usr/bin/virtualenv'}, 'proxyUser': 'jovyan', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "No active sessions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\": {\n",
    "        \"spark.pyspark.python\": \"python3\",\n",
    "        \"spark.pyspark.virtualenv.enabled\": \"true\",\n",
    "        \"spark.pyspark.virtualenv.type\":\"native\",\n",
    "        \"spark.pyspark.virtualenv.bin.path\":\"/usr/bin/virtualenv\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1685143379847_0002</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-78-219.ec2.internal:20888/proxy/application_1685143379847_0002/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-79-245.ec2.internal:8042/node/containerlogs/container_1685143379847_0002_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "Invalid package name: Package name and version must contain valid characters\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/context.py\", line 1178, in install_pypi_package\n",
      "    pypi_package = self._validate_package(pypi_package)\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/context.py\", line 1251, in _validate_package\n",
      "    raise ValueError(\"Invalid package name: Package name and version must contain valid characters\")\n",
      "ValueError: Invalid package name: Package name and version must contain valid characters\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package(\"boto3==1.19.2\")\n",
    "sc.install_pypi_package(\"pandas==1.0.5\")\n",
    "sc.install_pypi_package(\"scipy==1, key.4.1\")\n",
    "sc.install_pypi_package(\"matplotlib==3.2.1\")\n",
    "sc.install_pypi_package(\"seaborn==0.10.1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to S3 bucket with the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer, Word2Vec\n",
    "from pyspark.ml.feature import ElementwiseProduct, VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "bucket = 'scraped-data-zh'\n",
    "bucket_resource = s3.Bucket(bucket)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning function: convert json to Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function takes in a JSON and returns a Pandas DataFrame for easier operation. \n",
    "def stocktwits_json_to_df(data, key):\n",
    "    \n",
    "    columns = ['id','created_at','username','name','user_id','body','basic_sentiment','reshare_count']\n",
    "    df = pd.DataFrame(index=range(len(data)),columns=columns)\n",
    "    for i, message in enumerate(data):\n",
    "        df.loc[i,'id'] = message['id']\n",
    "        df.loc[i,'created_at'] = message['created_at']\n",
    "        df.loc[i,'username'] = message['user']['username']\n",
    "        df.loc[i,'name'] = message['user']['name']\n",
    "        df.loc[i,'user_id'] = message['user']['id']\n",
    "        df.loc[i,'body'] = message['body']\n",
    "        #We'll classify bullish as +1 and bearish as -1 to make it ready for classification training\n",
    "        try:\n",
    "            if (message['entities']['sentiment']['basic'] == 'Bullish'):\n",
    "                df.loc[i,'basic_sentiment'] = 1\n",
    "            elif (message['entities']['sentiment']['basic'] == 'Bearish'):\n",
    "                df.loc[i,'basic_sentiment'] = -1\n",
    "            else:\n",
    "                df.loc[i,'basic_sentiment'] = 0\n",
    "        except:\n",
    "                df.loc[i,'basic_sentiment'] = 0\n",
    "        try: \n",
    "            df.loc[i,'reshare_count'] = message['reshares']['reshared_count']\n",
    "        except:\n",
    "             df.loc[i,'reshare_count'] = 0\n",
    "        df[\"symbol\"] = key\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in json files and convert to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_dfs = []\n",
    "for i in bucket_resource.objects.all():\n",
    "    if 'json' in i.key:\n",
    "        obj = s3.Object(bucket, i.key)\n",
    "        string = obj.get()['Body'].read().decode('utf-8')\n",
    "        data = json.loads(string)\n",
    "        df = stocktwits_json_to_df(data, i.key[:-5])\n",
    "        list_dfs.append(df)\n",
    "        \n",
    "df = pd.concat(list_dfs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Columns: 9\n",
      "Total Rows: 269990\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- username: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- basic_sentiment: long (nullable = true)\n",
      " |-- reshare_count: long (nullable = true)\n",
      " |-- symbol: string (nullable = true)\n",
      "\n",
      "+---------+--------------------+--------------------+--------------------+-------+--------------------+---------------+-------------+------+\n",
      "|       id|          created_at|            username|                name|user_id|                body|basic_sentiment|reshare_count|symbol|\n",
      "+---------+--------------------+--------------------+--------------------+-------+--------------------+---------------+-------------+------+\n",
      "|529591661|2023-05-26T17:58:05Z|          Austin2980|          Austin2980|4401868|$AAPL really no m...|              0|            0|  AAPL|\n",
      "|529591424|2023-05-26T17:56:48Z|WolverineVcapitalllc| Albert J Xavier Jr.|3350195|         $AAPL $COST|              1|            0|  AAPL|\n",
      "|529591398|2023-05-26T17:56:41Z|          Electrolit|                 AKB|2229023|$AAPL pumping off...|              0|            0|  AAPL|\n",
      "|529591074|2023-05-26T17:55:00Z|magictape_behindw...|                 KTF|3578933|$SPY $QQQ $TSLA $...|              1|            0|  AAPL|\n",
      "|529591072|2023-05-26T17:55:00Z|           ChartMill|           ChartMill|  47688|In the last month...|              0|            0|  AAPL|\n",
      "|529590424|2023-05-26T17:51:51Z|           Sherry___|  Sherry, Not Shitty|1165200|$SPY $AAPL $SPY $...|             -1|            0|  AAPL|\n",
      "|529589910|2023-05-26T17:49:11Z|           Sherry___|  Sherry, Not Shitty|1165200|$SPY $AAPL $NVDA ...|             -1|            0|  AAPL|\n",
      "|529589596|2023-05-26T17:47:32Z|           crazzypro|       Prashant Goel|4288114|$SPY $QQQ $BTC $A...|              0|            0|  AAPL|\n",
      "|529589220|2023-05-26T17:45:24Z|         TheAliAbdul|           Ali abdul|6150060|$AAPL $178 by end...|              0|            0|  AAPL|\n",
      "|529588821|2023-05-26T17:43:13Z|    WallStreetBuyDip|    WallStreetBuyDip|6018168|$SPY $TSLA $AAPL ...|              0|            0|  AAPL|\n",
      "|529588724|2023-05-26T17:42:50Z|magictape_behindw...|                 KTF|3578933|$TSLA $SPY $AAPL ...|              1|            0|  AAPL|\n",
      "|529588515|2023-05-26T17:41:56Z|         IMakeMoney1|                Bori|6756957|$SPY Bears, even ...|              0|            0|  AAPL|\n",
      "|529588474|2023-05-26T17:41:43Z|             Augie84|            Cunterbi|1225883|          $AAPL $177|              1|            0|  AAPL|\n",
      "|529588435|2023-05-26T17:41:32Z| macrossluvsrobotech|              nomada|2231373|$ASXC Hello Child...|              1|            0|  AAPL|\n",
      "|529587824|2023-05-26T17:38:31Z|             JKool15|           John Kool|6294168|$TSLA like I said...|              1|            0|  AAPL|\n",
      "|529587822|2023-05-26T17:38:30Z|          Godoftrade|      Trading _Troll|1976085|               $AAPL|              0|            0|  AAPL|\n",
      "|529587566|2023-05-26T17:37:15Z|            4ProfitS|               steve|1124832|               $AAPL|             -1|            0|  AAPL|\n",
      "|529587066|2023-05-26T17:34:55Z|       Traderdogzz21|                  JC|5752120|$EPAZ~ expecting ...|              0|            0|  AAPL|\n",
      "|529587022|2023-05-26T17:34:45Z|    WallStreetBuyDip|    WallStreetBuyDip|6018168|My track record f...|              0|            0|  AAPL|\n",
      "|529586414|2023-05-26T17:32:15Z|              7feet7|hold to the moon ...|3480761|$AAPL  $180 next ...|              1|            0|  AAPL|\n",
      "+---------+--------------------+--------------------+--------------------+-------+--------------------+---------------+-------------+------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "sparkDF = spark.createDataFrame(df) \n",
    "\n",
    "print('Total Columns: %d' % len(sparkDF.dtypes))\n",
    "print('Total Rows: %d' % sparkDF.count())\n",
    "sparkDF.printSchema()\n",
    "sparkDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+\n",
      "|basic_sentiment| count|\n",
      "+---------------+------+\n",
      "|              1| 55528|\n",
      "|              0|191772|\n",
      "|             -1| 22690|\n",
      "+---------------+------+"
     ]
    }
   ],
   "source": [
    "sentiment_cnt = (sparkDF.groupBy('basic_sentiment').count())\n",
    "sentiment_cnt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|basic_sentiment|count|\n",
      "+---------------+-----+\n",
      "|              1|55528|\n",
      "|             -1|22690|\n",
      "+---------------+-----+"
     ]
    }
   ],
   "source": [
    "# 1 = bullish, -1 = bearish\n",
    "training_df = sparkDF.filter(\"basic_sentiment != 0\")\n",
    "sentiment_cnt = (training_df.groupBy('basic_sentiment').count())\n",
    "sentiment_cnt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_df = training_df.withColumn('is_bullish', (training_df.basic_sentiment == 1).cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"body\", outputCol=\"body_tokens\")\n",
    "w2v = Word2Vec(vectorSize=50, minCount=0, inputCol=\"body_tokens\", outputCol=\"body_vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "|symbol|symbol_index|\n",
      "+------+------------+\n",
      "|  AAPL|         7.0|\n",
      "|  AAPL|         7.0|\n",
      "|  AAPL|         7.0|\n",
      "|  AAPL|         7.0|\n",
      "|  AAPL|         7.0|\n",
      "|  AAPL|         7.0|\n",
      "|  AAPL|         7.0|\n",
      "|  AAPL|         7.0|\n",
      "|  AAPL|         7.0|\n",
      "|  AAPL|         7.0|\n",
      "|  AAPL|         7.0|\n",
      "|  AAPL|         7.0|\n",
      "|  AAPL|         7.0|\n",
      "|  AAPL|         7.0|\n",
      "|  AAPL|         7.0|\n",
      "|  AAPL|         7.0|\n",
      "|  AAPL|         7.0|\n",
      "|  AAPL|         7.0|\n",
      "|  AAPL|         7.0|\n",
      "|  AAPL|         7.0|\n",
      "+------+------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "indexer = StringIndexer(inputCol=\"symbol\", outputCol=\"symbol_index\")\n",
    "indexed = indexer.fit(training_df).transform(training_df)\n",
    "indexed['symbol', 'symbol_index'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+\n",
      "|symbol_index|    symbol_vec|\n",
      "+------------+--------------+\n",
      "|         7.0|(44,[7],[1.0])|\n",
      "|         7.0|(44,[7],[1.0])|\n",
      "|         7.0|(44,[7],[1.0])|\n",
      "|         7.0|(44,[7],[1.0])|\n",
      "|         7.0|(44,[7],[1.0])|\n",
      "|         7.0|(44,[7],[1.0])|\n",
      "|         7.0|(44,[7],[1.0])|\n",
      "|         7.0|(44,[7],[1.0])|\n",
      "|         7.0|(44,[7],[1.0])|\n",
      "|         7.0|(44,[7],[1.0])|\n",
      "|         7.0|(44,[7],[1.0])|\n",
      "|         7.0|(44,[7],[1.0])|\n",
      "|         7.0|(44,[7],[1.0])|\n",
      "|         7.0|(44,[7],[1.0])|\n",
      "|         7.0|(44,[7],[1.0])|\n",
      "|         7.0|(44,[7],[1.0])|\n",
      "|         7.0|(44,[7],[1.0])|\n",
      "|         7.0|(44,[7],[1.0])|\n",
      "|         7.0|(44,[7],[1.0])|\n",
      "|         7.0|(44,[7],[1.0])|\n",
      "+------------+--------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "encoder = OneHotEncoder(inputCols=[\"symbol_index\"], outputCols=[\"symbol_vec\"])\n",
    "encoded = encoder.fit(indexed).transform(indexed)\n",
    "encoded[[\"symbol_index\", \"symbol_vec\"]].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = ['symbol_vec', 'body_vec']\n",
    "assembler = VectorAssembler(inputCols = features, outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_pipeline = Pipeline(stages=[indexer, \n",
    "                               encoder, \n",
    "                               tokenizer, \n",
    "                               w2v,\n",
    "                               assembler])\n",
    "train = my_pipeline.fit(training_df).transform(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = LogisticRegression(featuresCol='features', labelCol='is_bullish')\n",
    "model = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.7278661243742433\n",
      "\n",
      "Training Accuracy: 0.7363906006290112"
     ]
    }
   ],
   "source": [
    "# Training Summary Data\n",
    "trainingSummary = model.summary\n",
    "\n",
    "print(\"Training AUC: \" + str(trainingSummary.areaUnderROC))\n",
    "print(\"\\nTraining Accuracy: \" + str(trainingSummary.accuracy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction_df = sparkDF.filter(\"basic_sentiment == 0\")\n",
    "prediction = my_pipeline.fit(prediction_df).transform(prediction_df)\n",
    "predicted_df = model.transform(prediction)\n",
    "out_df = predicted_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': 'PT2YMRXC5J729Q3M', 'HostId': 'PukbAPYjii4uxfMG4K4gfdDuVZCTKttu8PJ5KRVpLdabhLCYgmYoSHqmv8Ulx3QVwykSwbCeR1BAA7sNRKMv8g==', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amz-id-2': 'PukbAPYjii4uxfMG4K4gfdDuVZCTKttu8PJ5KRVpLdabhLCYgmYoSHqmv8Ulx3QVwykSwbCeR1BAA7sNRKMv8g==', 'x-amz-request-id': 'PT2YMRXC5J729Q3M', 'date': 'Fri, 26 May 2023 23:49:10 GMT', 'x-amz-server-side-encryption': 'AES256', 'etag': '\"9752be78fbc137a7a0fbc06172cccf20\"', 'server': 'AmazonS3', 'content-length': '0'}, 'RetryAttempts': 0}, 'ETag': '\"9752be78fbc137a7a0fbc06172cccf20\"', 'ServerSideEncryption': 'AES256'}"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "csv_buffer = StringIO()\n",
    "out_df.to_csv(csv_buffer)\n",
    "s3.Object(bucket, 'predictions.csv').put(Body=csv_buffer.getvalue())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
